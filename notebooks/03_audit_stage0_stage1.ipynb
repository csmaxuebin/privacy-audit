{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy Audit: Stage 0 (Base) vs Stage 1 (SFT)\n",
    "\n",
    "Compare canary memorization between the base Qwen2.5-0.5B model and the SFT fine-tuned model.\n",
    "\n",
    "Metrics: log-probability, top-k rank, membership inference signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers torch pandas peft accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.10.0+cu128\n",
      "CUDA available: True\n",
      "GPU: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT model found: ./qwen2_0p5b_sft_50\n",
      "Contents: ['training_args.bin', 'chat_template.jinja', 'README.md', 'checkpoint-200', 'adapter_model.safetensors', 'tokenizer_config.json', 'tokenizer.json', 'adapter_config.json', 'checkpoint-313']\n"
     ]
    }
   ],
   "source": [
    "# Auto-detect SFT model path\n",
    "sft_candidates = [\n",
    "    \"/qwen2_0p5b_sft_50\",\n",
    "    \"./qwen2_0p5b_sft_50\",\n",
    "]\n",
    "sft_dir = None\n",
    "for p in sft_candidates:\n",
    "    if os.path.exists(p):\n",
    "        sft_dir = p\n",
    "        break\n",
    "\n",
    "if sft_dir:\n",
    "    print(f\"SFT model found: {sft_dir}\")\n",
    "    print(\"Contents:\", os.listdir(sft_dir))\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        f\"SFT model not found in any candidate path: {sft_candidates}\\n\"\n",
    "        \"Please set sft_dir manually.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b648a498cd9c40cfb25d71d15336abbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13332754256142b0bfcf70e7d63eb3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bde11e07f92466bacfc56cdd75e4191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da83fe91cf7747a9a305fd34719882a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8619768293b41eaa6b25500d6a47dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01457d9c1db04dfd8f40ae3998bcf602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec45ddec17b498eb19b4fb6fd0a119e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/290 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee40360c27094da0b91258849184841d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model loaded: Qwen/Qwen2.5-0.5B-Instruct\n"
     ]
    }
   ],
   "source": [
    "# Load base model (Stage 0)\n",
    "base_model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_name, device_map=\"auto\")\n",
    "print(f\"Base model loaded: {base_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3afa1d1d44ab49d0b0d6d4ff3c9c0fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/290 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT model loaded from: ./qwen2_0p5b_sft_50\n"
     ]
    }
   ],
   "source": [
    "# Load SFT model (Stage 1)\n",
    "tokenizer = AutoTokenizer.from_pretrained(sft_dir)\n",
    "sft_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name, device_map=\"auto\"\n",
    ")\n",
    "sft_model = PeftModel.from_pretrained(sft_model, sft_dir)\n",
    "sft_model.eval()\n",
    "print(f\"SFT model loaded from: {sft_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canaries loaded: 50\n",
      "Normal controls: 50\n"
     ]
    }
   ],
   "source": [
    "# Load canary strings and control (normal) texts\n",
    "canary_candidates = [\"/data/canary_output.txt\", \"./data/canary_output.txt\"]\n",
    "wiki_candidates = [\"/data/wiki_trimmed_with_canary.jsonl\", \"./data/wiki_trimmed_with_canary.jsonl\"]\n",
    "\n",
    "canary_path = next((p for p in canary_candidates if os.path.exists(p)), None)\n",
    "wiki_path = next((p for p in wiki_candidates if os.path.exists(p)), None)\n",
    "\n",
    "if not canary_path:\n",
    "    raise FileNotFoundError(f\"Canary file not found: {canary_candidates}\")\n",
    "if not wiki_path:\n",
    "    raise FileNotFoundError(f\"Wiki file not found: {wiki_candidates}\")\n",
    "\n",
    "with open(canary_path) as f:\n",
    "    canaries = [l.strip() for l in f if l.strip()]\n",
    "\n",
    "with open(wiki_path) as f:\n",
    "    normal = [json.loads(l)[\"text\"] for l in f if \"CANARY\" not in l][:len(canaries)]\n",
    "\n",
    "print(f\"Canaries loaded: {len(canaries)}\")\n",
    "print(f\"Normal controls: {len(normal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logprob_of_sequence(model, tokenizer, prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    last_token_id = inputs[\"input_ids\"][0, -1]\n",
    "    logprob = outputs.logits[0, -1, last_token_id].item()\n",
    "    return logprob\n",
    "\n",
    "def topk_rank(model, tokenizer, prompt, target):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    last_logits = logits[0, -2]\n",
    "    sorted_indices = torch.argsort(last_logits, descending=True)\n",
    "    rank = (sorted_indices == tokenizer.encode(target)[-1]).nonzero().item()\n",
    "    return rank\n",
    "\n",
    "def membership_signal(model, tokenizer, text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "    return -outputs.loss.item()  # Higher = stronger memorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10/50 canaries\n",
      "Processed 20/50 canaries\n",
      "Processed 30/50 canaries\n",
      "Processed 40/50 canaries\n",
      "Processed 50/50 canaries\n",
      "Done. Total: 50 canaries audited.\n"
     ]
    }
   ],
   "source": [
    "# Run audit on canary strings\n",
    "results = []\n",
    "\n",
    "for i, canary in enumerate(canaries):\n",
    "    base_lp = logprob_of_sequence(base_model, base_tokenizer, canary)\n",
    "    sft_lp  = logprob_of_sequence(sft_model, tokenizer, canary)\n",
    "\n",
    "    base_rank = topk_rank(base_model, base_tokenizer, canary, canary)\n",
    "    sft_rank  = topk_rank(sft_model, tokenizer, canary, canary)\n",
    "\n",
    "    base_mem = membership_signal(base_model, base_tokenizer, canary)\n",
    "    sft_mem  = membership_signal(sft_model, tokenizer, canary)\n",
    "\n",
    "    results.append({\n",
    "        \"canary\": canary,\n",
    "        \"base_logprob\": base_lp,\n",
    "        \"sft_logprob\": sft_lp,\n",
    "        \"base_rank\": base_rank,\n",
    "        \"sft_rank\": sft_rank,\n",
    "        \"base_membership\": base_mem,\n",
    "        \"sft_membership\": sft_mem\n",
    "    })\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Processed {i + 1}/{len(canaries)} canaries\")\n",
    "\n",
    "print(f\"Done. Total: {len(results)} canaries audited.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: reports/privacy_audit_stage0_vs_stage1_50.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7de7adf2-ad24-4175-b03c-889e07123287\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canary</th>\n",
       "      <th>base_logprob</th>\n",
       "      <th>sft_logprob</th>\n",
       "      <th>base_rank</th>\n",
       "      <th>sft_rank</th>\n",
       "      <th>base_membership</th>\n",
       "      <th>sft_membership</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Canary 1: &lt;RARE_A&gt; DATA_IDENTIFIER_0ifd0tvbdivu</td>\n",
       "      <td>6.53125</td>\n",
       "      <td>6.25000</td>\n",
       "      <td>55</td>\n",
       "      <td>38</td>\n",
       "      <td>-7.553885</td>\n",
       "      <td>-7.485835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Canary 2: {CANARY_SEQ:hv3a3zmf8m|IDX=2519}</td>\n",
       "      <td>3.96875</td>\n",
       "      <td>4.28125</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.776380</td>\n",
       "      <td>-5.683955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Canary 3: {CANARY_SEQ:d4v30t9nt3|IDX=6925}</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.43750</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.822959</td>\n",
       "      <td>-5.535778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canary 4: &lt;STRUCT_ID&gt;_zbikcidk || dggvb tdlkh ...</td>\n",
       "      <td>4.46875</td>\n",
       "      <td>3.93750</td>\n",
       "      <td>185</td>\n",
       "      <td>260</td>\n",
       "      <td>-7.477756</td>\n",
       "      <td>-7.427140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canary 5: In conclusion, the following sequenc...</td>\n",
       "      <td>5.84375</td>\n",
       "      <td>5.71875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.950528</td>\n",
       "      <td>-5.941829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7de7adf2-ad24-4175-b03c-889e07123287')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-7de7adf2-ad24-4175-b03c-889e07123287 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-7de7adf2-ad24-4175-b03c-889e07123287');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              canary  base_logprob  \\\n",
       "0    Canary 1: <RARE_A> DATA_IDENTIFIER_0ifd0tvbdivu       6.53125   \n",
       "1         Canary 2: {CANARY_SEQ:hv3a3zmf8m|IDX=2519}       3.96875   \n",
       "2         Canary 3: {CANARY_SEQ:d4v30t9nt3|IDX=6925}       4.15625   \n",
       "3  Canary 4: <STRUCT_ID>_zbikcidk || dggvb tdlkh ...       4.46875   \n",
       "4  Canary 5: In conclusion, the following sequenc...       5.84375   \n",
       "\n",
       "   sft_logprob  base_rank  sft_rank  base_membership  sft_membership  \n",
       "0      6.25000         55        38        -7.553885       -7.485835  \n",
       "1      4.28125         11         0        -5.776380       -5.683955  \n",
       "2      4.43750          7         0        -5.822959       -5.535778  \n",
       "3      3.93750        185       260        -7.477756       -7.427140  \n",
       "4      5.71875          0         0        -5.950528       -5.941829  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save results to reports/\n",
    "os.makedirs(\"reports\", exist_ok=True)\n",
    "output_path = \"reports/privacy_audit_stage0_vs_stage1_50.csv\"\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Results saved to: {output_path}\")\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNDXLLpwpTRhczciLyuUbdK",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
