{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy Audit - DPO Ablation Training (Stage 2)\n",
    "\n",
    "Train two DPO variants for canary ablation experiment:\n",
    "- **Section A**: DPO-no-canary (preference data without canary pairs)\n",
    "- **Section B**: DPO-with-canary (preference data with canary pairs)\n",
    "\n",
    "Both variants use the same SFT base model and identical hyperparameters.\n",
    "\n",
    "**Prerequisites:**\n",
    "1. Upload the following files to Colab:\n",
    "   - `data/wiki_trimmed_with_canary.jsonl`\n",
    "   - `data/canary_output.txt`\n",
    "   - `models/stage1_sft/` folder\n",
    "   - `src/prepare_preference_data.py`\n",
    "   - `src/train_dpo.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets transformers peft trl accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu126\n",
      "CUDA available: True\n",
      "GPU: Tesla T4\n",
      "GPU Memory: 15.8 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"Warning: No GPU detected. DPO training requires a GPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [OK] SFT model directory: ./stage1_sft\n",
      "  [OK] Wiki data file: ./data/wiki_trimmed_with_canary.jsonl\n",
      "  [OK] Canary file: ./data/canary_output.txt\n",
      "  [OK] Preference data script: ./src/prepare_preference_data.py\n",
      "  [OK] DPO training script: ./src/train_dpo.py\n",
      "\n",
      "All files verified!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Base model (downloaded from HuggingFace)\n",
    "BASE_MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "# Uploaded paths (adjust based on your Colab upload location)\n",
    "SFT_MODEL_DIR = \"./stage1_sft\"\n",
    "WIKI_FILE = \"./data/wiki_trimmed_with_canary.jsonl\"\n",
    "CANARY_FILE = \"./data/canary_output.txt\"\n",
    "PREPARE_SCRIPT = \"./src/prepare_preference_data.py\"\n",
    "TRAIN_SCRIPT = \"./src/train_dpo.py\"\n",
    "\n",
    "# Output paths\n",
    "DATA_NO_CANARY = \"./data/preference_data_no_canary.jsonl\"\n",
    "DATA_WITH_CANARY = \"./data/preference_data_with_canary.jsonl\"\n",
    "OUTPUT_NO_CANARY = \"./stage2_dpo_no_canary\"\n",
    "OUTPUT_WITH_CANARY = \"./stage2_dpo_with_canary\"\n",
    "\n",
    "# Verify uploaded files\n",
    "required_files = [\n",
    "    (SFT_MODEL_DIR, \"SFT model directory\"),\n",
    "    (WIKI_FILE, \"Wiki data file\"),\n",
    "    (CANARY_FILE, \"Canary file\"),\n",
    "    (PREPARE_SCRIPT, \"Preference data script\"),\n",
    "    (TRAIN_SCRIPT, \"DPO training script\"),\n",
    "]\n",
    "all_ok = True\n",
    "for path, desc in required_files:\n",
    "    exists = os.path.exists(path)\n",
    "    status = \"OK\" if exists else \"MISSING\"\n",
    "    print(f\"  [{status}] {desc}: {path}\")\n",
    "    if not exists:\n",
    "        all_ok = False\n",
    "\n",
    "if all_ok:\n",
    "    print(\"\\nAll files verified!\")\n",
    "else:\n",
    "    print(\"\\nSome files are missing. Please upload them before proceeding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Preference Data (Two Variants)\n",
    "\n",
    "Generate both no-canary and with-canary preference data using the same seed.\n",
    "Normal preference pairs will be identical across both variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading data...\n",
      "[INFO] Loaded 10000 wiki texts, 10 canaries\n",
      "[INFO] Generating no-canary variant (seed=42)...\n",
      "[DONE] Saved 1912 pairs to data/preference_data_no_canary.jsonl\n",
      "[INFO] Generating with-canary variant (seed=42)...\n",
      "[DONE] Saved 1932 pairs to data/preference_data_with_canary.jsonl\n",
      "[INFO] Verifying data equivalence...\n",
      "[OK] Normal preference pairs are identical across variants.\n"
     ]
    }
   ],
   "source": [
    "# Generate both variants\n",
    "!python {PREPARE_SCRIPT} --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no-canary: 1912 pairs\n",
      "  Sample prompt: Summarize the following text in one sentence:\n",
      "\n",
      "Yener Yörük (born May 25, 1963 in...\n",
      "with-canary: 1932 pairs\n",
      "  Sample prompt: Summarize the following text in one sentence:\n",
      "\n",
      "Yener Yörük (born May 25, 1963 in...\n"
     ]
    }
   ],
   "source": [
    "# Verify generated files\n",
    "import json\n",
    "\n",
    "for path, label in [(DATA_NO_CANARY, \"no-canary\"), (DATA_WITH_CANARY, \"with-canary\")]:\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "    print(f\"{label}: {len(lines)} pairs\")\n",
    "    sample = json.loads(lines[0])\n",
    "    print(f\"  Sample prompt: {sample['prompt'][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Section A: Train DPO-no-canary\n",
    "\n",
    "Train DPO using preference data **without** canary pairs.\n",
    "Output: `models/stage2_dpo_no_canary/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Privacy Audit - DPO Training (Stage 2)\n",
      "============================================================\n",
      "[INFO] Treating --base-model as HuggingFace model ID: Qwen/Qwen2.5-0.5B-Instruct\n",
      "\n",
      "[INFO] Loading tokenizer...\n",
      "[OK] Tokenizer loaded. Vocab size: 151665\n",
      "\n",
      "[INFO] Loading SFT model (Stage 1)...\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading weights: 100% 290/290 [00:00<00:00, 770.08it/s, Materializing param=model.norm.weight]                              \n",
      "[OK] SFT model loaded!\n",
      "\n",
      "[INFO] Loading preference dataset from ./data/preference_data_no_canary.jsonl...\n",
      "[OK] Dataset loaded. Number of examples: 1912\n",
      "[INFO] Sample data: {'prompt': 'Summarize the following text in one sentence:\\n\\nYener Yörük (born May 25, 1963 in Manisa) is a Turkish physician specialising in thoracic surgery, a university professor, and Chancellor (Rector) of the Trakya University, Edirne 2012-2016.\\n\\nBiograph', 'chosen': 'The text discusses Yener Yörük (born May 25, 1963 in Manisa)...', 'rejected': 'This is not relevant to my knowledge.'}\n",
      "\n",
      "[INFO] Configuring DPO Trainer...\n",
      "[OK] DPO Trainer initialized!\n",
      "\n",
      "============================================================\n",
      "[INFO] Starting DPO training...\n",
      "  preference-data: ./data/preference_data_no_canary.jsonl\n",
      "  output-dir:      ./stage2_dpo_no_canary\n",
      "  sft-model:       ./stage1_sft\n",
      "  base-model:      Qwen/Qwen2.5-0.5B-Instruct\n",
      "============================================================\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
      "{'loss': '0.3856', 'grad_norm': '2.313', 'learning_rate': '4.625e-05', 'rewards/chosen': '2.764', 'rewards/rejected': '0.1369', 'rewards/accuracies': '0.7437', 'rewards/margins': '2.627', 'logps/chosen': '-280.7', 'logps/rejected': '-77.5', 'logits/chosen': '-1.611', 'logits/rejected': '-0.9842', 'epoch': '0.08368'}\n",
      "{'loss': '0.3026', 'grad_norm': '1.211', 'learning_rate': '4.208e-05', 'rewards/chosen': '3.64', 'rewards/rejected': '0.07158', 'rewards/accuracies': '0.8313', 'rewards/margins': '3.568', 'logps/chosen': '-304.4', 'logps/rejected': '-77.62', 'logits/chosen': '-1.761', 'logits/rejected': '-1.142', 'epoch': '0.1674'}\n",
      "{'loss': '0.3623', 'grad_norm': '1.376', 'learning_rate': '3.792e-05', 'rewards/chosen': '2.844', 'rewards/rejected': '0.1793', 'rewards/accuracies': '0.8062', 'rewards/margins': '2.665', 'logps/chosen': '-275.6', 'logps/rejected': '-86.57', 'logits/chosen': '-1.604', 'logits/rejected': '-1.122', 'epoch': '0.251'}\n",
      "{'loss': '0.4073', 'grad_norm': '1.25', 'learning_rate': '3.375e-05', 'rewards/chosen': '2.815', 'rewards/rejected': '0.08109', 'rewards/accuracies': '0.7375', 'rewards/margins': '2.734', 'logps/chosen': '-271.7', 'logps/rejected': '-76.35', 'logits/chosen': '-1.555', 'logits/rejected': '-0.9787', 'epoch': '0.3347'}\n",
      "{'loss': '0.3155', 'grad_norm': '1.42', 'learning_rate': '2.958e-05', 'rewards/chosen': '3.2', 'rewards/rejected': '0.07805', 'rewards/accuracies': '0.825', 'rewards/margins': '3.122', 'logps/chosen': '-274.3', 'logps/rejected': '-80.05', 'logits/chosen': '-1.656', 'logits/rejected': '-1.171', 'epoch': '0.4184'}\n",
      "{'loss': '0.3222', 'grad_norm': '2.065', 'learning_rate': '2.542e-05', 'rewards/chosen': '3.353', 'rewards/rejected': '0.08358', 'rewards/accuracies': '0.7812', 'rewards/margins': '3.27', 'logps/chosen': '-309.6', 'logps/rejected': '-79.78', 'logits/chosen': '-1.748', 'logits/rejected': '-1.093', 'epoch': '0.5021'}\n",
      "{'loss': '0.3243', 'grad_norm': '1.329', 'learning_rate': '2.125e-05', 'rewards/chosen': '3.406', 'rewards/rejected': '0.1226', 'rewards/accuracies': '0.7875', 'rewards/margins': '3.283', 'logps/chosen': '-355.4', 'logps/rejected': '-86.7', 'logits/chosen': '-1.742', 'logits/rejected': '-1.065', 'epoch': '0.5858'}\n",
      "{'loss': '0.393', 'grad_norm': '1.819', 'learning_rate': '1.708e-05', 'rewards/chosen': '2.906', 'rewards/rejected': '0.0961', 'rewards/accuracies': '0.775', 'rewards/margins': '2.81', 'logps/chosen': '-275.6', 'logps/rejected': '-82.75', 'logits/chosen': '-1.666', 'logits/rejected': '-0.9894', 'epoch': '0.6695'}\n",
      "{'loss': '0.3626', 'grad_norm': '1.288', 'learning_rate': '1.292e-05', 'rewards/chosen': '3.084', 'rewards/rejected': '0.08535', 'rewards/accuracies': '0.7937', 'rewards/margins': '2.998', 'logps/chosen': '-274.2', 'logps/rejected': '-83.74', 'logits/chosen': '-1.687', 'logits/rejected': '-1.107', 'epoch': '0.7531'}\n",
      "{'loss': '0.3788', 'grad_norm': '2.329', 'learning_rate': '8.75e-06', 'rewards/chosen': '2.914', 'rewards/rejected': '0.1139', 'rewards/accuracies': '0.7937', 'rewards/margins': '2.8', 'logps/chosen': '-263.4', 'logps/rejected': '-74.95', 'logits/chosen': '-1.629', 'logits/rejected': '-1.036', 'epoch': '0.8368'}\n",
      "{'loss': '0.3696', 'grad_norm': '1.802', 'learning_rate': '4.583e-06', 'rewards/chosen': '3.31', 'rewards/rejected': '0.08137', 'rewards/accuracies': '0.775', 'rewards/margins': '3.229', 'logps/chosen': '-290.8', 'logps/rejected': '-81.35', 'logits/chosen': '-1.668', 'logits/rejected': '-1.149', 'epoch': '0.9205'}\n",
      "{'loss': '0.3479', 'grad_norm': '1.791', 'learning_rate': '4.167e-07', 'rewards/chosen': '3.062', 'rewards/rejected': '0.06331', 'rewards/accuracies': '0.7829', 'rewards/margins': '2.998', 'logps/chosen': '-287.2', 'logps/rejected': '-86.24', 'logits/chosen': '-1.704', 'logits/rejected': '-1.039', 'epoch': '1'}\n",
      "{'train_runtime': '1650', 'train_samples_per_second': '1.159', 'train_steps_per_second': '0.073', 'train_loss': '0.356', 'epoch': '1'}\n",
      "100% 120/120 [27:29<00:00, 13.75s/it]\n",
      "\n",
      "[INFO] Saving DPO model to ./stage2_dpo_no_canary...\n",
      "[DONE] DPO model saved to ./stage2_dpo_no_canary\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!python {TRAIN_SCRIPT} \\\n",
    "    --preference-data {DATA_NO_CANARY} \\\n",
    "    --output-dir {OUTPUT_NO_CANARY} \\\n",
    "    --sft-model {SFT_MODEL_DIR} \\\n",
    "    --base-model {BASE_MODEL_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPO-no-canary model files:\n",
      "total 19660\n",
      "drwxr-xr-x 4 root root     4096 Feb 10 08:01 .\n",
      "drwxr-xr-x 1 root root     4096 Feb 10 07:04 ..\n",
      "-rw-r--r-- 1 root root      980 Feb 10 08:01 adapter_config.json\n",
      "-rw-r--r-- 1 root root  8663400 Feb 10 08:01 adapter_model.safetensors\n",
      "-rw-r--r-- 1 root root     2507 Feb 10 08:01 chat_template.jinja\n",
      "drwxr-xr-x 2 root root     4096 Feb 10 07:56 checkpoint-100\n",
      "drwxr-xr-x 2 root root     4096 Feb 10 08:01 checkpoint-120\n",
      "-rw-r--r-- 1 root root     2472 Feb 10 08:01 README.md\n",
      "-rw-r--r-- 1 root root      665 Feb 10 08:01 tokenizer_config.json\n",
      "-rw-r--r-- 1 root root 11421892 Feb 10 08:01 tokenizer.json\n",
      "-rw-r--r-- 1 root root     6097 Feb 10 08:01 training_args.bin\n"
     ]
    }
   ],
   "source": [
    "# Verify no-canary model output\n",
    "print(\"DPO-no-canary model files:\")\n",
    "!ls -la {OUTPUT_NO_CANARY}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Section B: Train DPO-with-canary\n",
    "\n",
    "Train DPO using preference data **with** canary pairs.\n",
    "Output: `models/stage2_dpo_with_canary/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Privacy Audit - DPO Training (Stage 2)\n",
      "============================================================\n",
      "[INFO] Treating --base-model as HuggingFace model ID: Qwen/Qwen2.5-0.5B-Instruct\n",
      "\n",
      "[INFO] Loading tokenizer...\n",
      "[OK] Tokenizer loaded. Vocab size: 151665\n",
      "\n",
      "[INFO] Loading SFT model (Stage 1)...\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading weights: 100% 290/290 [00:00<00:00, 905.28it/s, Materializing param=model.norm.weight]                              \n",
      "[OK] SFT model loaded!\n",
      "\n",
      "[INFO] Loading preference dataset from ./data/preference_data_with_canary.jsonl...\n",
      "Generating train split: 1932 examples [00:00, 228773.76 examples/s]\n",
      "[OK] Dataset loaded. Number of examples: 1932\n",
      "[INFO] Sample data: {'prompt': 'Summarize the following text in one sentence:\\n\\nYener Yörük (born May 25, 1963 in Manisa) is a Turkish physician specialising in thoracic surgery, a university professor, and Chancellor (Rector) of the Trakya University, Edirne 2012-2016.\\n\\nBiograph', 'chosen': 'The text discusses Yener Yörük (born May 25, 1963 in Manisa)...', 'rejected': 'This is not relevant to my knowledge.'}\n",
      "\n",
      "[INFO] Configuring DPO Trainer...\n",
      "Extracting prompt in train dataset: 100% 1932/1932 [00:00<00:00, 10155.70 examples/s]\n",
      "Applying chat template to train dataset: 100% 1932/1932 [00:00<00:00, 11914.67 examples/s]\n",
      "Tokenizing train dataset: 100% 1932/1932 [00:02<00:00, 935.39 examples/s]\n",
      "[OK] DPO Trainer initialized!\n",
      "\n",
      "============================================================\n",
      "[INFO] Starting DPO training...\n",
      "  preference-data: ./data/preference_data_with_canary.jsonl\n",
      "  output-dir:      ./stage2_dpo_with_canary\n",
      "  sft-model:       ./stage1_sft\n",
      "  base-model:      Qwen/Qwen2.5-0.5B-Instruct\n",
      "============================================================\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
      "{'loss': '0.3622', 'grad_norm': '1.875', 'learning_rate': '4.628e-05', 'rewards/chosen': '2.946', 'rewards/rejected': '0.1463', 'rewards/accuracies': '0.7937', 'rewards/margins': '2.8', 'logps/chosen': '-284.4', 'logps/rejected': '-88.75', 'logits/chosen': '-1.635', 'logits/rejected': '-1.172', 'epoch': '0.08282'}\n",
      "{'loss': '0.3726', 'grad_norm': '1.741', 'learning_rate': '4.215e-05', 'rewards/chosen': '3.157', 'rewards/rejected': '0.08532', 'rewards/accuracies': '0.7688', 'rewards/margins': '3.072', 'logps/chosen': '-306.1', 'logps/rejected': '-80.11', 'logits/chosen': '-1.664', 'logits/rejected': '-1.071', 'epoch': '0.1656'}\n",
      "{'loss': '0.3351', 'grad_norm': '1.49', 'learning_rate': '3.802e-05', 'rewards/chosen': '3.137', 'rewards/rejected': '0.08579', 'rewards/accuracies': '0.8062', 'rewards/margins': '3.052', 'logps/chosen': '-279.2', 'logps/rejected': '-86.14', 'logits/chosen': '-1.657', 'logits/rejected': '-1.072', 'epoch': '0.2484'}\n",
      "{'loss': '0.2986', 'grad_norm': '1.284', 'learning_rate': '3.388e-05', 'rewards/chosen': '3.639', 'rewards/rejected': '0.07583', 'rewards/accuracies': '0.8375', 'rewards/margins': '3.563', 'logps/chosen': '-345.7', 'logps/rejected': '-87.51', 'logits/chosen': '-1.751', 'logits/rejected': '-1.172', 'epoch': '0.3313'}\n",
      "{'loss': '0.3895', 'grad_norm': '1.448', 'learning_rate': '2.975e-05', 'rewards/chosen': '2.902', 'rewards/rejected': '0.108', 'rewards/accuracies': '0.7625', 'rewards/margins': '2.794', 'logps/chosen': '-267', 'logps/rejected': '-87.54', 'logits/chosen': '-1.599', 'logits/rejected': '-1.05', 'epoch': '0.4141'}\n",
      "{'loss': '0.4093', 'grad_norm': '1.448', 'learning_rate': '2.562e-05', 'rewards/chosen': '2.638', 'rewards/rejected': '0.03538', 'rewards/accuracies': '0.725', 'rewards/margins': '2.603', 'logps/chosen': '-243.7', 'logps/rejected': '-71.18', 'logits/chosen': '-1.618', 'logits/rejected': '-1.047', 'epoch': '0.4969'}\n",
      "{'loss': '0.3565', 'grad_norm': '1.926', 'learning_rate': '2.149e-05', 'rewards/chosen': '3.11', 'rewards/rejected': '0.1323', 'rewards/accuracies': '0.7625', 'rewards/margins': '2.977', 'logps/chosen': '-294.7', 'logps/rejected': '-72.29', 'logits/chosen': '-1.659', 'logits/rejected': '-1.008', 'epoch': '0.5797'}\n",
      "{'loss': '0.3585', 'grad_norm': '1.878', 'learning_rate': '1.736e-05', 'rewards/chosen': '3.155', 'rewards/rejected': '0.1069', 'rewards/accuracies': '0.775', 'rewards/margins': '3.048', 'logps/chosen': '-306', 'logps/rejected': '-84.11', 'logits/chosen': '-1.691', 'logits/rejected': '-1.087', 'epoch': '0.6625'}\n",
      "{'loss': '0.3469', 'grad_norm': '1.725', 'learning_rate': '1.322e-05', 'rewards/chosen': '3.198', 'rewards/rejected': '0.1452', 'rewards/accuracies': '0.7875', 'rewards/margins': '3.053', 'logps/chosen': '-298.9', 'logps/rejected': '-77.95', 'logits/chosen': '-1.702', 'logits/rejected': '-1.083', 'epoch': '0.7453'}\n",
      "{'loss': '0.2941', 'grad_norm': '0.9577', 'learning_rate': '9.091e-06', 'rewards/chosen': '3.761', 'rewards/rejected': '0.096', 'rewards/accuracies': '0.8625', 'rewards/margins': '3.665', 'logps/chosen': '-312.2', 'logps/rejected': '-80.59', 'logits/chosen': '-1.695', 'logits/rejected': '-1.118', 'epoch': '0.8282'}\n",
      "{'loss': '0.3866', 'grad_norm': '1.675', 'learning_rate': '4.959e-06', 'rewards/chosen': '2.74', 'rewards/rejected': '0.1137', 'rewards/accuracies': '0.7812', 'rewards/margins': '2.626', 'logps/chosen': '-266.4', 'logps/rejected': '-78.18', 'logits/chosen': '-1.606', 'logits/rejected': '-0.9926', 'epoch': '0.911'}\n",
      "{'loss': '0.3755', 'grad_norm': '1.995', 'learning_rate': '8.264e-07', 'rewards/chosen': '2.702', 'rewards/rejected': '0.08812', 'rewards/accuracies': '0.7812', 'rewards/margins': '2.614', 'logps/chosen': '-248.8', 'logps/rejected': '-81.39', 'logits/chosen': '-1.641', 'logits/rejected': '-1.127', 'epoch': '0.9938'}\n",
      "{'train_runtime': '1658', 'train_samples_per_second': '1.165', 'train_steps_per_second': '0.073', 'train_loss': '0.3592', 'epoch': '1'}\n",
      "100% 121/121 [27:37<00:00, 13.70s/it]\n",
      "\n",
      "[INFO] Saving DPO model to ./stage2_dpo_with_canary...\n",
      "[DONE] DPO model saved to ./stage2_dpo_with_canary\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!python {TRAIN_SCRIPT} \\\n",
    "    --preference-data {DATA_WITH_CANARY} \\\n",
    "    --output-dir {OUTPUT_WITH_CANARY} \\\n",
    "    --sft-model {SFT_MODEL_DIR} \\\n",
    "    --base-model {BASE_MODEL_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPO-with-canary model files:\n",
      "total 19660\n",
      "drwxr-xr-x 4 root root     4096 Feb 10 08:32 .\n",
      "drwxr-xr-x 1 root root     4096 Feb 10 07:04 ..\n",
      "-rw-r--r-- 1 root root      980 Feb 10 08:32 adapter_config.json\n",
      "-rw-r--r-- 1 root root  8663400 Feb 10 08:32 adapter_model.safetensors\n",
      "-rw-r--r-- 1 root root     2507 Feb 10 08:32 chat_template.jinja\n",
      "drwxr-xr-x 2 root root     4096 Feb 10 08:27 checkpoint-100\n",
      "drwxr-xr-x 2 root root     4096 Feb 10 08:32 checkpoint-121\n",
      "-rw-r--r-- 1 root root     2476 Feb 10 08:32 README.md\n",
      "-rw-r--r-- 1 root root      665 Feb 10 08:32 tokenizer_config.json\n",
      "-rw-r--r-- 1 root root 11421892 Feb 10 08:32 tokenizer.json\n",
      "-rw-r--r-- 1 root root     6097 Feb 10 08:32 training_args.bin\n"
     ]
    }
   ],
   "source": [
    "# Verify with-canary model output\n",
    "print(\"DPO-with-canary model files:\")\n",
    "!ls -la {OUTPUT_WITH_CANARY}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. (Optional) Upload Models to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to mount Google Drive and copy models\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "#\n",
    "# import shutil\n",
    "# drive_dest = \"/content/drive/MyDrive/privacy-audit/models\"\n",
    "# os.makedirs(drive_dest, exist_ok=True)\n",
    "#\n",
    "# shutil.copytree(OUTPUT_NO_CANARY, f\"{drive_dest}/stage2_dpo_no_canary\", dirs_exist_ok=True)\n",
    "# shutil.copytree(OUTPUT_WITH_CANARY, f\"{drive_dest}/stage2_dpo_with_canary\", dirs_exist_ok=True)\n",
    "# print(\"Models uploaded to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Download Models\n",
    "\n",
    "Download the trained models to your local machine:\n",
    "- Right-click the model directories in the Colab file browser to download\n",
    "- Or use the zip cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /content/stage2_dpo_no_canary.zip\n",
      "Created /content/stage2_dpo_with_canary.zip\n",
      "\n",
      "Download these zip files and extract to:\n",
      "  models/stage2_dpo_no_canary/\n",
      "  models/stage2_dpo_with_canary/\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Zip no-canary model\n",
    "shutil.make_archive(\"/content/stage2_dpo_no_canary\", 'zip', OUTPUT_NO_CANARY)\n",
    "print(\"Created /content/stage2_dpo_no_canary.zip\")\n",
    "\n",
    "# Zip with-canary model\n",
    "shutil.make_archive(\"/content/stage2_dpo_with_canary\", 'zip', OUTPUT_WITH_CANARY)\n",
    "print(\"Created /content/stage2_dpo_with_canary.zip\")\n",
    "\n",
    "print(\"\\nDownload these zip files and extract to:\")\n",
    "print(\"  models/stage2_dpo_no_canary/\")\n",
    "print(\"  models/stage2_dpo_with_canary/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPO ablation training complete!\n",
      "  No-canary model: ./stage2_dpo_no_canary\n",
      "  With-canary model: ./stage2_dpo_with_canary\n"
     ]
    }
   ],
   "source": [
    "print(\"DPO ablation training complete!\")\n",
    "print(f\"  No-canary model: {OUTPUT_NO_CANARY}\")\n",
    "print(f\"  With-canary model: {OUTPUT_WITH_CANARY}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
