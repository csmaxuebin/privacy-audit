{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy Audit - DPO Training (Stage 2)\n",
    "\n",
    "使用 DPO 对 SFT 模型进行偏好优化，观察隐私风险在 preference optimization 阶段的变化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets transformers peft trl accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 挂载 Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "DATA_DIR = \"/content/drive/MyDrive/PrivacyAudit\"\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Contents: {os.listdir(DATA_DIR)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 检查 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 配置路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置\n",
    "BASE_MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "SFT_MODEL_DIR = f\"{DATA_DIR}/qwen2_0p5b_sft_A100\"  # Stage 1 输出\n",
    "PREFERENCE_DATA = f\"{DATA_DIR}/preference_data.jsonl\"\n",
    "OUTPUT_DIR = f\"{DATA_DIR}/stage2_dpo\"\n",
    "\n",
    "print(f\"Base model: {BASE_MODEL_NAME}\")\n",
    "print(f\"SFT model: {SFT_MODEL_DIR}\")\n",
    "print(f\"Preference data: {PREFERENCE_DATA}\")\n",
    "print(f\"Output: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 加载模型和数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "from trl import DPOTrainer, DPOConfig\n",
    "\n",
    "# 加载 tokenizer\n",
    "print(\"[INFO] Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "print(f\"[OK] Tokenizer loaded. Vocab size: {len(tokenizer)}\")\n",
    "\n",
    "# 加载 base model\n",
    "print(\"[INFO] Loading base model...\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "print(\"[OK] Base model loaded!\")\n",
    "\n",
    "# 加载 SFT adapter\n",
    "print(\"[INFO] Loading SFT adapter (Stage 1)...\")\n",
    "model = PeftModel.from_pretrained(base_model, SFT_MODEL_DIR)\n",
    "print(\"[OK] SFT model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载偏好数据\n",
    "print(\"[INFO] Loading preference dataset...\")\n",
    "dataset = load_dataset(\"json\", data_files=PREFERENCE_DATA, split=\"train\")\n",
    "print(f\"[OK] Dataset loaded. Number of examples: {len(dataset)}\")\n",
    "print(f\"[INFO] Sample: {dataset[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 配置 DPO Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Configuring DPO Trainer...\")\n",
    "\n",
    "dpo_config = DPOConfig(\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    beta=0.1,\n",
    "    max_length=512,\n",
    "    max_prompt_length=256,\n",
    "    bf16=True,\n",
    ")\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=None,\n",
    "    args=dpo_config,\n",
    "    train_dataset=dataset,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "print(\"[OK] DPO Trainer initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"[INFO] Starting DPO training (Stage 2)...\")\n",
    "print(\"=\" * 60)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Saving DPO model...\")\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(f\"[DONE] DPO model saved to {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 验证模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证保存的模型\n",
    "print(f\"[INFO] Verifying saved model...\")\n",
    "print(f\"Contents of {OUTPUT_DIR}:\")\n",
    "print(os.listdir(OUTPUT_DIR))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
